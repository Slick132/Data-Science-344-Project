{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('FinalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_values = data.isnull().sum()\n",
    "duplicates = data.duplicated(subset='computed_key').sum()\n",
    "# Check the distribution of genres\n",
    "genre_distribution = data['genre'].value_counts()\n",
    "data = data.drop(columns=['liveness','artist_name', 'track_name','computed_key','year','danceability','energy','key','loudness','mode',\t\"speechiness\",\t'acousticness',\t'instrumentalness',\t'liveness','valence', 'tempo',\t'duration_ms' ,'time_signature'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()\n",
    "data.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a value is numeric\n",
    "def is_numeric(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Columns to check for conflicting data types\n",
    "columns_to_check = ['genre']\n",
    "\n",
    "# Identify rows with conflicting data types in each column\n",
    "rows_to_drop = set()\n",
    "\n",
    "for column in columns_to_check:\n",
    "    for index, value in data[column].items():\n",
    "        if is_numeric(value):\n",
    "            rows_to_drop.add(index)\n",
    "\n",
    "# Drop rows with conflicting data types\n",
    "cleaned_data = data.drop(rows_to_drop)\n",
    "\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Numbers, punctiations and lowercasing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rid_of_specials(words):\n",
    "    new= ''\n",
    "    for i in range(len(words)):\n",
    "        a = re.sub('[^A-Za-z]+', ' ', words[i]).lower()\n",
    "        new += a\n",
    "    return new\n",
    "data[\"lyrics\"] = data[\"lyrics\"].apply(rid_of_specials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "sw_nltk = (stopwords.words('english'))\n",
    "stop_words = set(sw_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(x):\n",
    "    x = x.split(' ')\n",
    "    return  ' '.join(z for z in x if z not in stop_words)\n",
    "stopped = data[\"lyrics\"].apply(remove_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize words\n",
    "Since Lemmatization understands / considers context and works with the english language as a whole, stemming can be disadvantageous when used in certain words. For example, one word can have different lemmas depending on how it is used. Stemming does not consider this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# Step 1\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Step 2\n",
    "lemmatized = [lemmatizer.lemmatize(i) for i in stopped]\n",
    "# Step 3\n",
    "prepeared_sentence = [''.join(j) for j in lemmatized]\n",
    "data['Lyrics_Processed'] = prepeared_sentence\n",
    "data['Lyrics_Processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# To make the language detection deterministic\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Function to detect language\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "data = data[data['lyrics'].apply(is_english)]\n",
    "data = data.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Filterd.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
