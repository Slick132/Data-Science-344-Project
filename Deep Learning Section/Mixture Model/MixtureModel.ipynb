{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/24694266/DataScience344/Project/RNNModels/Filterd.csv\"\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 songs\n",
    "data_sample = data.sample(n=50000, random_state=42)\n",
    "\n",
    "# Extract features and target variable\n",
    "X = data_sample[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', \n",
    "                 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', \n",
    "                 'duration_ms', 'time_signature']]\n",
    "y = data_sample['genre']\n",
    "\n",
    "# Convert genres to numerical labels\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# One-hot encode the 'time_signature' column\n",
    "time_signature_dummies = pd.get_dummies(X['time_signature'], prefix='time_signature')\n",
    "X = pd.concat([X.drop('time_signature', axis=1), time_signature_dummies], axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features (excluding one-hot encoded columns)\n",
    "columns_to_scale = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', \n",
    "                   'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', \n",
    "                   'duration_ms']\n",
    "scaler = StandardScaler()\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Check and handle missing values\n",
    "if X_train.isnull().sum().sum() > 0:\n",
    "    X_train.fillna(X_train.mean(), inplace=True)\n",
    "\n",
    "if X_test.isnull().sum().sum() > 0:\n",
    "    X_test.fillna(X_test.mean(), inplace=True)\n",
    "    # Convert labels to one-hot encoded format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# Tokenize and pad the lyrics\n",
    "maxlen = 30\n",
    "tokenizer = Tokenizer()\n",
    "train_data = pd.read_csv(\"DataMixtureModel.csv\")\n",
    "# Assuming `data` is your dataset\n",
    "data_sample = train_data.sample(n=1000, random_state=42)\n",
    "train_data, test_data = train_test_split(data_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer.fit_on_texts(train_data['Lyrics_Processed'])\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['Lyrics_Processed'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['Lyrics_Processed'])\n",
    "\n",
    "padded_sequences_train = pad_sequences(train_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "padded_sequences_test = pad_sequences(test_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "# One-hot encode genres\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_train = label_encoder.fit_transform(train_data['genre'])\n",
    "integer_encoded_test = label_encoder.transform(test_data['genre'])\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_train = integer_encoded_train.reshape(len(integer_encoded_train), 1)\n",
    "integer_encoded_test = integer_encoded_test.reshape(len(integer_encoded_test), 1)\n",
    "\n",
    "y_train = encoder.fit_transform(integer_encoded_train)\n",
    "y_test = encoder.transform(integer_encoded_test)\n",
    "\n",
    "# Scale features\n",
    "features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', \n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', \n",
    "            'duration_ms', 'time_signature']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_features = scaler.fit_transform(train_data[features]).astype(np.float32)\n",
    "X_test_features = scaler.transform(test_data[features]).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, concatenate\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define max words and embedding dimension\n",
    "\n",
    "max_words = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 30\n",
    "\n",
    "# LSTM model for Lyrics\n",
    "lyrics_input = Input(shape=(maxlen,), name='lyrics_input')\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=maxlen)(lyrics_input)\n",
    "embedding_dropout = Dropout(0.5)(embedding_layer)\n",
    "lstm_1 = LSTM(64, return_sequences=True, dropout=0.4, recurrent_dropout=0.4, kernel_regularizer=l2(0.01))(embedding_dropout)\n",
    "lstm_dropout_1 = Dropout(0.4)(lstm_1)\n",
    "lstm_2 = LSTM(64, dropout=0.4, recurrent_dropout=0.4, kernel_regularizer=l2(0.01))(lstm_dropout_1)\n",
    "lstm_dropout_2 = Dropout(0.4)(lstm_2)\n",
    "dense_lyrics = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(lstm_dropout_2)\n",
    "dropout_lyrics = Dropout(0.5)(dense_lyrics)\n",
    "\n",
    "# FFNN model for Numerical Features\n",
    "features_input = Input(shape=(X_train_features.shape[1],), name='features_input')\n",
    "dense_features_1 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(features_input)\n",
    "dropout_features_1 = Dropout(0.5)(dense_features_1)\n",
    "dense_features_2 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(dropout_features_1)\n",
    "dropout_features_2 = Dropout(0.5)(dense_features_2)\n",
    "\n",
    "# Merge the outputs of the two branches\n",
    "merged = concatenate([dropout_lyrics, dropout_features_2])\n",
    "\n",
    "# Add the final output layer\n",
    "output = Dense(len(y_train.unique()), activation='softmax')(merged)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=[lyrics_input, features_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=64, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training history\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Over Epochs')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
